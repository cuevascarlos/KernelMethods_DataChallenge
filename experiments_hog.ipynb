{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernels import RBF, LinearKernel\n",
    "from classifiers import KernelSVC, MulticlassKernelSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "\n",
    "#Read training data\n",
    "Xtr = np.array(pd.read_csv(data_path+'Xtr.csv',header=None,sep=',',usecols=range(3072))) #Drop the last column of Xtr because it is generated by the format of the data but it is unnecessary.\n",
    "Ytr = np.array(pd.read_csv(data_path+'Ytr.csv',sep=',',usecols=[1])).squeeze() \n",
    "\n",
    "#Read test data\n",
    "Xte = np.array(pd.read_csv(data_path+'/Xte.csv',header=None,sep=',',usecols=range(3072))) ##Drop the last column of Xte because it is generated by the format of the data but it is unnecessary.\n",
    "\n",
    "# define your learning algorithm here \n",
    "# # for instance, define an object called ``classifier'' \n",
    "# # classifier.train(Ytr,Xtr) \n",
    "# # predict on the test data \n",
    "# # for instance, Yte = classifier.fit(Xte) \n",
    "# Yte = {'Prediction' : Yte} \n",
    "# dataframe = pd.DataFrame(Yte) dataframe.index += 1 \n",
    "# dataframe.to_csv('Yte_pred.csv',index_label='Id') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training data into a training and a validation set\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(Xtr, Ytr, test_size=0.2, random_state=42, stratify=Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data classes count: {0: 400, 1: 400, 2: 400, 3: 400, 4: 400, 5: 400, 6: 400, 7: 400, 8: 400, 9: 400}\n",
      "Validation data classes count: {0: 100, 1: 100, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100}\n"
     ]
    }
   ],
   "source": [
    "#Check that the distribution of the labels is the same in the training and validation set\n",
    "unique, counts = np.unique(Y_train, return_counts=True)\n",
    "print(f\"Training data classes count: {dict(zip(unique, counts))}\")\n",
    "\n",
    "unique, counts = np.unique(Y_val, return_counts=True)\n",
    "print(f\"Validation data classes count: {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation for training\n",
    "X_train_augmented, Y_train_augmented = flip_augmentation(X_train, Y_train)\n",
    "X_train_augmented, Y_train_augmented = rotate_dataset(X_train_augmented, Y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply hog features extraction\n",
    "hog_model = hog_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hog = hog_model.fit_extract(X_train_augmented, Y_train_augmented)\n",
    "X_val_hog = hog_model.extract_features(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the kernel and the classifier\n",
    "kernel = RBF(sigma=1.6)\n",
    "multiKSVC = MulticlassKernelSVC(C=1, kernel=kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building K...\n",
      "Building K - done\n",
      "Building K...\n",
      "Building K - done\n",
      "Building K...\n",
      "Building K - done\n",
      "Building K...\n",
      "Building K - done\n",
      "Building K...\n",
      "Building K - done\n",
      "Building K...\n",
      "Building K - done\n",
      "Building K...\n",
      "Building K - done\n",
      "Building K...\n",
      "Building K - done\n",
      "Building K...\n",
      "Building K - done\n",
      "Building K...\n",
      "Building K - done\n"
     ]
    }
   ],
   "source": [
    "multiKSVC.fit(X_train_hog, Y_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = multiKSVC.predict(X_val_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.505"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred == Y_val)/len(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the prediction and generate the csv file to uplode for the challenge\n",
    "Xte_hog = hog_model.extract_features(Xte)\n",
    "Yte = multiKSVC.predict(Xte_hog) \n",
    "Yte = {'Prediction' : Yte} \n",
    "dataframe = pd.DataFrame(Yte) \n",
    "dataframe.index += 1 \n",
    "dataframe.to_csv('./Yte_pred_hog.csv',index_label='Id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
